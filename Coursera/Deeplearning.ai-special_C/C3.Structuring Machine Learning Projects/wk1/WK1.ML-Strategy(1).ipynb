{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy;Copyright for [Shuang Wu] [2017]<br>\n",
    "Cite from the [coursera] named [Neural network and Machine Learning] from [deeplearning.ai]<br>\n",
    "Learning notes<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to ML Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why ML Strategy\n",
    "\n",
    "* Motivating example\n",
    "    * cat classification\n",
    "        * Ideas:\n",
    "            * Collect more data\n",
    "            * Collect more diverse training set\n",
    "            * Train algorithm longer w/ GD\n",
    "            * Try Adam instead of GD\n",
    "            * Try bigger network\n",
    "            * try smaller network\n",
    "            * try dropout\n",
    "            * add L2 regularization\n",
    "            * ...\n",
    "* help choose the way to improve the model\n",
    "* effective to geting DL work\n",
    "\n",
    "## Orthogonalization\n",
    "\n",
    "* TV tuning example\n",
    "    * ![img1](imgs/img1.jpg)\n",
    "    * ![img2](imgs/img2.jpg)\n",
    "* Chain of asuumption in ML\n",
    "    * Fit training set well on cost func.\n",
    "        * $\\approx$ humman-level performance\n",
    "        * bigger network\n",
    "        * adam\n",
    "    * Fit dev set well on cost function\n",
    "        * regularization\n",
    "        * bigger training set\n",
    "    * Fit test set well on cost function\n",
    "        * bigger dev set\n",
    "    * Performs well in real world\n",
    "        * change dev set or cost function\n",
    "* not use early stopping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up your goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single number evaluation metric\n",
    "    \n",
    "* Using a single number evaluation metric\n",
    "    * ![img3](imgs/img3.jpg)\n",
    "    * Precision: number of examples recognized as cat, what % actually are casts?\n",
    "    * Recall: what % of actual cats are corectely recognized?\n",
    "    * $F_1$ score = \"Average\" of P at R\n",
    "        * Harmonic mean: $\\frac{2}{\\frac{1}{p}+\\frac{1}{R}}$\n",
    "        * ![img4](imgs/img4.jpg)\n",
    "    * (Dev set + single real number evalutation matrie) will speed up iteration\n",
    "* Another example\n",
    "    * ![img5](imgs/img5.jpg)\n",
    "    * pick up the lower one and iterate on that one\n",
    "    \n",
    "## Satisficing and Optimizing metric\n",
    "\n",
    "* Another cat classification example\n",
    "    * ![img6](imgs/img6.jpg)\n",
    "    * Cost = accuracy - 0.5 * running time\n",
    "    * Maxmize accuracy subject to running time $\\leq$ 100ms\n",
    "    * N matrix: 1 optimizaing, n-1 satisfiaing\n",
    "\n",
    "## Train/dev/test distributions\n",
    "\n",
    "* Cat classification dev/test sets\n",
    "    * development set, hold out cross validation set\n",
    "    * should come from the same distribution\n",
    "    * ![img7](imgs/img7.jpg)\n",
    "* True story\n",
    "    * Optimizing on dev set on loan approvals for medium income zip codes\n",
    "        * x to y (repay loan)\n",
    "        * Tested on low income zip codes (~3 month)\n",
    "* Guideline\n",
    "    * Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on\n",
    "        * dev and test should be same distribution\n",
    "\n",
    "## Size of the dev and test sets\n",
    "\n",
    "* Old way of splitting data\n",
    "    * Old way of splitting data \n",
    "    <table>\n",
    "    <caption></caption>\n",
    "    <tbody>\n",
    "        <tr> \n",
    "          <td> **Train** </td>\n",
    "          <td> **Dev** </td>\n",
    "          <td> **Test** </td>\n",
    "          </tr>\n",
    "          <tr> \n",
    "          <td> 70% </td>\n",
    "          <td> 0 </td>\n",
    "          <td> 30% </td>\n",
    "          </tr>\n",
    "          <tr> \n",
    "          <td> 60% </td>\n",
    "          <td> 20% </td>\n",
    "          <td> 20% </td>\n",
    "          </tr>\n",
    "    </tbody>\n",
    "    </table>\n",
    "    * for 100, 1000, 10000 e.g.s\n",
    "    * for large data set 1,000,000\n",
    "        * 98% train\n",
    "        * 1% dev\n",
    "        * 1% test\n",
    "* Size of test set\n",
    "    * Set your test set to be big enough to give high confidence in the overall performance of your system\n",
    "    * Train + dev is ok: no test set ok\n",
    "* When to change dev/test sets and metrics\n",
    "    * Cat dataset examples\n",
    "        * Metric: classification error\n",
    "        * Alg. A: 3% error\n",
    "            * pornographic\n",
    "        * Alg. B: 5% error\n",
    "            * this one better than A because no pornographic\n",
    "        * Metric + dev prefer A\n",
    "        * user prefer B\n",
    "    * Error: $\\frac{1}{m_{dev}}\\sum^{m_dev}_{i=1}w^{(i)}*I\\{y_{pred}^{(i)}\\neq y^{(i)}\\}$\n",
    "        * $w^{(i)}=\\begin{cases}\n",
    "        1\\quad \\text{if x is non-porn} \\\\\n",
    "        0\\quad \\text{if x is porn}\\\\\n",
    "        \\end{cases}$\n",
    "* Orthogonalization for cat pictures: anti-porn\n",
    "    * so far we've only discussed how to define a metric to evaluate classifiers\n",
    "        * place target\n",
    "    * Worry separately about how to do well on this metric\n",
    "        * aim/shoot at target\n",
    "    * $J=\\frac{1}{m}\\sum^m_{i=1}w*l(\\hat{y},y)$\n",
    "* Another example\n",
    "    * Alg. A : 3% error\n",
    "    * Alg. B : 5% error\n",
    "    * ![img8](imgs/img8.jpg)\n",
    "    * Alg. B maybe better\n",
    "    * If doing well on your metric + dev/test set does not correspond to doing well on your application, change your metric and/or dev/test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing to human-level performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why human-level performance\n",
    "\n",
    "* Comparing to human-level performance\n",
    "    * ![img9](imgs/img9.jpg)\n",
    "* Why compare to human-level performance\n",
    "    * Humans are quite good at a lot of tasks. So long as ML is worse than humans you can:\n",
    "        * Get labeled data from humans (x,y)\n",
    "        * Gain insight from manmual error analysis: why did a person get this right?\n",
    "        * Better analysis of bias/variance\n",
    "\n",
    "## Cat classification example\n",
    "\n",
    "* Cat classification e.g.\n",
    "    * Errors on cat classification\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td>**Humans($\\approx$Bayes)**</td>\n",
    "            <td>1%</td>\n",
    "            <td>7.5%</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>**Training error**</td>\n",
    "            <td>8%</td>\n",
    "            <td>8%</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>**Dev error**</td>\n",
    "            <td>10%</td>\n",
    "            <td>10%</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td>Focus on reduce bias</td>\n",
    "            <td>Focus on reduce variance</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    * Human-level error as a proxy/estimate for Bayes opt. error\n",
    "\n",
    "## Understanding human-level performance\n",
    "\n",
    "* Human-level error as a proxy for Bayes error\n",
    "    * Medical image classification e.g.:\n",
    "        * suppose:\n",
    "            * Typical human w/ 3% error\n",
    "            * Typical doctor w/ 1% error\n",
    "            * Experienced doctor w/ 0.7% error\n",
    "            * Team of experienced doctors w/ 0.5% error\n",
    "            * Bayes error $\\leq0.5\\%$\n",
    "        * What is \"human-level\"\n",
    "            * maybe 0.5%\n",
    "* Error analysis example\n",
    "    * ![img10](imgs/img10.jpg)\n",
    "    \n",
    "* Summary of bias/variance w/ human-level performance\n",
    "    * Human-level error\n",
    "        * bias\n",
    "    * Training error\n",
    "        * variance\n",
    "    * Dev error\n",
    "    \n",
    "## Surpassing human-level performance\n",
    "\n",
    "* Surpassing human-level performance\n",
    "    * team of human 0.5%\n",
    "    * one human 1%\n",
    "    * train 0.6%\n",
    "    * dev error 0.8%\n",
    "        * bias will be 0.1%\n",
    "        * variance will be 0.2%\n",
    "    * but\n",
    "        * ![img11](imgs/img11.jpg)\n",
    "\n",
    "* Problems where ML significantly surpasses human-level performance\n",
    "    * online advertising\n",
    "    * product recommendations\n",
    "    * logistics (predicting transit time)\n",
    "    * loan approvals\n",
    "        * learn from structed data\n",
    "        * not natural perception\n",
    "        * lots of data\n",
    "    * maybe diff. for the following\n",
    "        * speech recognation\n",
    "        * some image recognation\n",
    "        * medical\n",
    "            * ECG, skin cancer, ...\n",
    "\n",
    "## Improving your model performance\n",
    "\n",
    "* The two funndamental assumptions of supervised learning\n",
    "    * you can fit the training set pretty well. (bias)\n",
    "    * The training set performance generalizes pretty well to the dev/test set. (variance)\n",
    "* Reducing (avoidable) bias and variance\n",
    "    * Human-level\n",
    "        * bias\n",
    "            * train bigger model\n",
    "            * train longer/better optimization alg.\n",
    "                * momentum, RMSprop, Adam\n",
    "            * NN architecture/hyperparameters search\n",
    "                * RNN, CNN\n",
    "    * Training error\n",
    "        * Variance\n",
    "            * More data\n",
    "            * Regularization\n",
    "                * l2, dropout, data augmentation\n",
    "            * NN architecture/hyperparameters search\n",
    "    * Dev error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
