{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy;Copyright for [Shuang Wu] [2017]<br>\n",
    "Cite from the [coursera] named [Neural network for Machine Learning] from [University of Toronto]<br>\n",
    "Learning notes<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the weights of a linear neuron\n",
    "\n",
    "## Why perceptron procedure cannot be generalised to hidden layers\n",
    "\n",
    "* Perceptron convergence procedure works by ensure every time the weights change, get closer to every \"generously feasible\" set of weights\n",
    "    * cannot extended to more complex networks which average of two good solutions may be a bad one.\n",
    "* multi-layer NN do not use perceptron learning procedure\n",
    "\n",
    "## Diff. way to show learning procedure makes progress\n",
    "\n",
    "* Show the output values get closer to the target values, not the weights get closer to good set of weights\n",
    "    * True even for non-convex problems\n",
    "        * average two give bad in non0convex\n",
    "    * not true for perceptron learning\n",
    "* e.g.: linear neuron w/ a squared error measure\n",
    "\n",
    "## Linear neurons (linear filters)\n",
    "\n",
    "* Neuron has a real-valued output which is a weighted sum of its inputs\n",
    "* $y=\\sum_iw_ix_i=\\vec{w}^T\\vec{x}$\n",
    "    * $y$: neuron's estimate of the desired output\n",
    "    * $\\vec{w}$ weight vec.\n",
    "    * $\\vec{x}$ input vec.\n",
    "* Aim of learning is to minimize the error summed over all training cases\n",
    "    * error is the squared defference b/w the desired output and the actual output\n",
    "    \n",
    "## Why not solve analytically\n",
    "\n",
    "* Standard engineering approach\n",
    "    * write down set of equations, one per training case, and solve for the best set of weights\n",
    "* **Scientific**: want a method that real neurons could use\n",
    "* **Engineering**: want a method that can generalized to multi-layer, non-linear NN\n",
    "    * analytic solution relies on it being linear and having a squared error measure\n",
    "    * iterative methods usually less efficient but they are much easier to generalize\n",
    "    \n",
    "## sSToy e.g. for iterative method\n",
    "\n",
    "* Each day lunch at the Cafe\n",
    "    * diet consists of fish, chips and ketchup\n",
    "    * several portions of each\n",
    "* Cashier only tells the total price of the meal\n",
    "    * several days later, you may figure out the price for each\n",
    "* The ite approach: start w/ random guesses for the prices and adjust to get the better fit to the observed prices of whole meals\n",
    "\n",
    "## Solving the equations iteratively\n",
    "\n",
    "*  $price = x_{fish}w_{fish}+x_{chips}w_{chips}+x_{ketcp}w_{ketcp}$\n",
    "    * Linear constraint on the prices\n",
    "* $\\vec{w} = (w_{fist}, w_{chips}, w_{ketcp})$\n",
    "    * weights in of a linear neuron\n",
    "* start w/ guesses for the w8 and then adjust the guesses slightly to a better fit to the actual one.\n",
    "* **True** w8 used by the cashier\n",
    "    * ![img29](imgs/img29.jpg)\n",
    "\n",
    "## Model the cashier w/ arbitrary initial weigths\n",
    "\n",
    "* initial guess\n",
    "    * ![img30](imgs/img30.jpg)\n",
    "    * residual error = 350\n",
    "    * \"Delta-rule\" for learning: $\\Delta w_i=\\epsilon x_i(t-y)$\n",
    "    * w/ $\\epsilon = 1/35$, weight changes are:+20, +50, +30\n",
    "    * new weights: 70, 100, 80\n",
    "        * make the chips weight worse\n",
    "        \n",
    "## Deriving delta rule\n",
    "\n",
    "* Define the error as the squared residuals summed over all training\n",
    "    * $$E=\\frac{1}{2}\\sum_{n\\in training}(t^n-y^n)^2$$\n",
    "* Differentiate to get error derivatives for weights\n",
    "    * $$\\frac{\\partial E}{\\partial w_i} = \\frac{1}{2}\\sum_n\\frac{\\partial y^n}{\\partial w_i}\\frac{dE^n}{dy^n} = -\\sum_n x_i^n(t^n-y^n)$$\n",
    "* Batch delta rule changes the weights in proportion to their error derivatives summed over all training\n",
    "    * $$\\Delta w_i=-\\epsilon\\frac{\\partial E}{\\partial w_i}=\\sum_n\\epsilon x^n_i(t^n-y^n)$$\n",
    "    \n",
    "## Behav. of the itera. learning procedure\n",
    "\n",
    "* Does the learning procedure eventually get the right ans?\n",
    "    * no perfect answer\n",
    "    * by making the learning rate small enough, can get as close as we desire to the best answer\n",
    "* How quickly the weights converge?\n",
    "    * Can be very slow if 2 input dim. are highly correlated. If almost always have the same # of portions of ketp and chips, hard to decide how to divide the price between ketp and chips.\n",
    "    \n",
    "## Ralationship b/w online delta-rule and learning rule for perceptrons\n",
    "\n",
    "* Perceptron\n",
    "    * increment or decrement the weight vec. by the input vec.\n",
    "    * only change the weights when make an error\n",
    "* Online delta-rule\n",
    "    * increment or decrement the weight vec. by the input vec. scaled by the residual error and the learning rate\n",
    "    * need to choose the learning rate, annoying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error surface for a linear neuron\n",
    "\n",
    "## Error surface in extended w8 space\n",
    "\n",
    "* Error surface lies in a space w/ a horizontal axis for each w8 and one vertical axis for error\n",
    "    * linear neuron w/ squared error, quadratic bowl\n",
    "    * vertical cross-sections are parabolas\n",
    "    * horizontal cross-sections are ellipses\n",
    "* Multi-layer, non-linear nets, the surface much more complicated\n",
    "    * ![img31](imgs/img31.jpg)\n",
    "    \n",
    "## Online versus batch learning\n",
    "\n",
    "* Simplest kind of batch learning does steepest descent on the error surface\n",
    "    * travels perpendicular to the contour lines\n",
    "    * ![img32](imgs/img32.jpg)\n",
    "* simplest kind of online learning zig-zags around the direction of steepest descent\n",
    "    * ![img33](imgs/img33.jpg)\n",
    "    \n",
    "## Why learning can be slow\n",
    "\n",
    "* ![img34](imgs/img34.jpg)\n",
    "* If ellipse is elongated, direction of steepest descent is almost perpendicular to the direction to wards the minumum\n",
    "    * red gradient vec. has large component along the short axis of the ellipse and small component along the long axis of the ellipse\n",
    "    * the opposite of what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the w8 of a logistic output neuron\n",
    "\n",
    "## Logistic neurons\n",
    "\n",
    "* These give a real-valued output that smooth and bounded function of their total input\n",
    "    * nice derivatives make learning eash\n",
    "    * $$z=b+\\sum_i x_iw_i$$\n",
    "    * $$y=\\frac{1}{1+e^{-z}}$$\n",
    "    * ![img35](imgs/img35.jpg)\n",
    "    \n",
    "## Derivatives of logistic neuron\n",
    "\n",
    "* Derivatives of the logit, z, w.r.t the inputs and the weights are: $$z=b+\\sum_i x_iw_i$$\n",
    "    * $$\\frac{\\partial z}{\\partial w_i}=x_i\\quad \\quad \\frac{\\partial z}{\\partial x_i}=w_i$$\n",
    "* Derivative of the output w.r.t the logit is simple if express it in terms of the output: $$y= \\frac{1}{1+e^{-z}}$$\n",
    "    * $$\\frac{dy}{dz}=y(1-y)$$\n",
    "$$y= \\frac{1}{1+e^{-z}}=(1+e^{-z})^{-1}$$\n",
    "$$\\frac{dy}{dz} = \\frac{-1(-e^{-z})}{(1+e^{-z})^2}=\\frac{1}{1+e^{-z}}\\frac{e^{-z}}{1+e^{-z}}=y(1-y)$$\n",
    "\n",
    "## Using the chain rule to get the derivatives needed for learning the w8 of a logistic unit\n",
    "\n",
    "* To learn the w8 need the derivative of the output w.r.t each weight:\n",
    "    * $$\\frac{\\partial y}{\\partial w_i}= \\frac{\\partial z}{\\partial w_i}\\frac{dy}{dz}=x_i y(1-y)$$<br>\n",
    "    * <br>\n",
    "    * $$\\frac{\\partial E}{\\partial w_i} = \\sum_n\\frac{\\partial y^n}{\\partial w_i}\\frac{\\partial E}{\\partial y^n}=-\\sum_n x_i^n y^n(1-y^n)(t^n-y^n)$$\n",
    "        * $x_i^n$ and $(t^n-y^n)$ is the <font color='red'>delta-rule</font>\n",
    "        * $y^n(1-y^n)$ is the  <font color='green'>extra term, same as the slope of logistic</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation algo.\n",
    "\n",
    "## Learning w/ hidden units (again)\n",
    "\n",
    "* Networks w/o hidden units limited in the input-output mappings they can model\n",
    "* Adding a layer of hand-coded features ( perceptron) makes much more powerful but hard designing the features\n",
    "    * like to find good features w/o requiring insights into the task or repeated trial and error where we guess some features and see how well they work\n",
    "* need to automate the loop of designing features for particular task and seeing how well it does\n",
    "\n",
    "## Learning by perturbing weights\n",
    "\n",
    "* Randomly perturb one weight and see if improves performance, if so , save the change\n",
    "    * form of reinforcement learning\n",
    "    * <font color='red'>Inefficient</font>. Need multiple forward passes on a representative set of training cases just to change one weight. Back pro. much better\n",
    "    * towards the end of learning, large weight perturbations nearly always make things <font color='red'>worse</font>, b/c weights need to have the right relative values\n",
    "    * ![img36](imgs/img36.jpg)\n",
    "    \n",
    "## Learning by using perturbations\n",
    "\n",
    "* Could randomly perturb all weights in parallel and correlate the performance gain w/ the weight changes\n",
    "    * not any better, b/c need lots of trials on each training case to 'see' the effect of changing one w8 through the noise created by all the changes to other w8\n",
    "* Better idea: Randomly perturb the activities of the hidden units\n",
    "    * once know how want a hidden activity to change on given training, can compute how to change the w8\n",
    "    * there are fewer activities than weights, but backpropagation still wins by a factor of the # of neurons.\n",
    "    \n",
    "## Idea behind backpropagation\n",
    "\n",
    "* Dont't know the hidden units ought to do, but can compute how fast the error changes as we change a hidden activity\n",
    "    * use <font color='red'>error derivatives w.r.t. hidden activities</font>, instead of using desired activities to train the hidden units\n",
    "    * Each hidden activity can affect many output units and can therefore have many separate effects on the error. These effects must be combined\n",
    "* Can compute error derivatives for all hidden units efficiently at same time\n",
    "    * once have the error derivatives for hidden activities, easy to get the error derivatives for the weights going into a hidden unit\n",
    "    \n",
    "## Sketch of the backpropagation algo. on a single case\n",
    "\n",
    "* 1st, conver the discrepancy b/w each output and its target value into an error derivative\n",
    "    * $$E=\\frac{1}{2}\\sum_{j\\in output}(t_j-y_j)^2$$\n",
    "* 2nd, compute error derivatives in each hidden layer from error derivatives in the layer above\n",
    "    * $$\\frac{\\partial E}{\\partial y_j}=-(t_j-y_j)$$\n",
    "* 3rd, use error derivatives w.r.t. activiteis to get error derivatives w.r.t. incoming weights\n",
    "    * ![img37](imgs/img37.jpg)\n",
    "    \n",
    "## Backpropagating $dE/dy$\n",
    "\n",
    "* $$\\frac{\\partial E}{\\partial z_j} = \\frac{dy_j}{dz_j}\\frac{\\partial E}{\\partial y_j} = y_j(1-y_j)\\frac{\\partial E}{\\partial y_j}$$\n",
    "* \n",
    "* $$\\frac{\\partial E}{\\partial y_i} = \\sum_j\\frac{dz_j}{dy_i}\\frac{\\partial E}{\\partial z_j}=\\sum_jw_{ij}\\frac{\\partial E}{\\partial z_j}$$\n",
    "* \n",
    "* $$\\frac{\\partial E}{\\partial w_{ij}} = \\frac{\\partial z_j}{\\partial w_{ij}}\\frac{\\partial E}{\\partial z_j}=y_i\\frac{\\partial E}{\\partial z_j}$$\n",
    "* ![img38](imgs/img38.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the derivatives computed by the backpropagation alg.\n",
    "\n",
    "## Converting error derivatives into learning procedure\n",
    "\n",
    "* backpropagation alg. is an efficient way of computing error derivative $dE/dw$ for every w8 on single training case\n",
    "* need make lot of other decision about error derivatives to get fully specified learning procedure\n",
    "    * **Optimization**: use error derivatives on individual cases to discover good set of w8 (wk 6)\n",
    "    * **Generalization**: ensure learned w8 work well for cases we did not see during training (wk 7)\n",
    "* now have brief overview of these 2 sets of issues\n",
    "\n",
    "## Optim. issues in using the weight derivatives\n",
    "\n",
    "* How often to update the w8\n",
    "    * online: after each training\n",
    "    * Full batch: after full sweep trough the traning\n",
    "    * Mini-batch: after small sample of training\n",
    "* How much to update (futher in wk 6)\n",
    "    * Fixed learning rate?\n",
    "    * Adapt global learning rate?\n",
    "    * Adapt learning rate on each connection separately?\n",
    "    * Not use steepest descent?\n",
    "    \n",
    "## Overfitting: downside of using poerful modes\n",
    "\n",
    "*  Training contains info. about regularities in mapping from input to output. But also contains 2 type of noise\n",
    "    * target val. may be unreliable (usually only a minor worry)\n",
    "    * <font color='red'>Sampling error</font>. there will be accidental regularities just b/c of the particular training that were chosen\n",
    "* When fit model, it cannot tell which regularities are real and which are caused by sampling error\n",
    "    * So it fits both kinds of regularity\n",
    "    * if model flexible it can model the sampling error really well. <font color='red'>This is disaster</font>\n",
    "    \n",
    "## Simple e.g. of overfitting\n",
    "\n",
    "* Model trust:\n",
    "    * Complicated model fits data better\n",
    "    * not economical\n",
    "* Model is convincing when fits a lot of data surprisingly well\n",
    "    * not surprising that complicated model can fit a small amount of data well\n",
    "![img39](imgs/img39.jpg)\n",
    "\n",
    "## Ways to reduce overfitting\n",
    "\n",
    "* lots of diff. method\n",
    "    * w8-decay\n",
    "    * w8-sharing\n",
    "    * early stop\n",
    "    * model averaging\n",
    "    * Bayesian fitting of NN\n",
    "    * dropout\n",
    "    * generative pre-training\n",
    "* detail in wk 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
