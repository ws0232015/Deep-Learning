{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy;Copyright for [Shuang Wu] [2017]<br>\n",
    "Cite from the [coursera] named [Neural network and Machine Learning] from [deeplearning.ai]<br>\n",
    "Learning notes<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep L-layer NN\n",
    "\n",
    "* DIff. type of networks\n",
    "    * Logistic regression\n",
    "        * ![img43](imgs/img43.jpg)\n",
    "        * shallow\n",
    "        * 1 layer NN\n",
    "    * 1-hidden layer\n",
    "        * ![img44](imgs/img44.jpg)\n",
    "        * 2 layer NN\n",
    "    * 2-hidden layers\n",
    "        * ![img45](imgs/img45.jpg)\n",
    "    * 5-hidden layers\n",
    "        * ![img46](imgs/img46.jpg)\n",
    "        * Deep\n",
    "* Deep NN\n",
    "    * ![img47](imgs/img47.jpg)\n",
    "        * $L=4$ # of layers\n",
    "        * $n^{[L]}$ # of units/neurons in layer L\n",
    "            * $n^{[1]}=5$\n",
    "            * $n^{[2]}=5$\n",
    "            * $n^{[3]}=3$\n",
    "            * $n^{[4]}=1$\n",
    "            * $n^{[0]}=n_x=3$\n",
    "        * $a^{[L]}$ avtivations in layer L\n",
    "            * $a^{[L]}=g(z^{[L]})$\n",
    "            * $a^{[L]}=x$\n",
    "        * $w^{[L]}$ weights for $z^{[L]}$\n",
    "        * $b^{[L]}$ bias for $z^{[L]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation in deep net.\n",
    "\n",
    "* For layer 1\n",
    "    * $z^{[1]} = w^{[1]}a^{[0]}+b^{[1]}$\n",
    "        * $x = a^{[0]}$\n",
    "    * $a^{[1]}=g^{[1]}(z^{[1]})$\n",
    "* For layer 2\n",
    "    * $z^{[2]} = w^{[2]}a^{[1]}+b^{[2]}$\n",
    "    * $a^{[2]}=g^{[2]}(z^{[2]})$\n",
    "* $\\cdots$\n",
    "* Layer 4\n",
    "    * $z^{[4]} = w^{[4]}a^{[3]}+b^{[4]}$\n",
    "    * $a^{[4]}=g^{[4]}(z^{[4]})=\\hat{y}$\n",
    "* For lyaer i\n",
    "    * $z^{[i]} = w^{[i]}a^{[i-1]}+b^{[i]}$\n",
    "    * $a^{[i]}=g^{[i]}(z^{[i]})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting your matrix dimensions right\n",
    "\n",
    "* $w^{[L]}$ and $b^{[L]}$\n",
    "    * $w^{[L]}$dimension: ($n^{[L]}$, $n^{[L-1]}$)\n",
    "    * $b^{[L]}$dimension: ($n^{[L]}$, 1)\n",
    "\n",
    "* Vec. implementation\n",
    "    * $Z^{[1]} = W^{[L]}X + b^{[L]}$\n",
    "        * $Z^{[1]}$dimension: ($n^{[1]}$, $m$)\n",
    "        * $A^{[1]}$dimension: ($n^{[1]}$, $m$)\n",
    "        * same as dZ and dA\n",
    "        * $A^{[0]}=X$dimension: ($n^{[0]}$, $m$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why deeo representations\n",
    "\n",
    "* Intuition\n",
    "    * Picture\n",
    "        * first layer figure out the edges\n",
    "        * ![img48](imgs/img48.jpg)\n",
    "    * Audio (speak recognition)\n",
    "        * low level audio waveform\n",
    "        * phonenes\n",
    "            * C \n",
    "            * A\n",
    "            * T\n",
    "        * Word\n",
    "        * Sentence/ phrase\n",
    "* Circuit theory and DL\n",
    "    * Informally: there are func. you can compute w/ a small L-layer deep NN that shallower networks require exponentially more hidden units to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building blocks of deep NN\n",
    "\n",
    "* Forward and backward func.\n",
    "    * ![img49](imgs/img49.jpg)\n",
    "        * update for each of the layer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward and backward propagation\n",
    "* Forward\n",
    "    * Input: $a^{[l-1]}$\n",
    "    * Output: $a^{[l]}$, cache: ($z^{[l]}$, $w^{[l]}$, $b^{[l]}$)\n",
    "    * Cal eq.:\n",
    "        * $z^{[l]}=w^{[l]}\\cdot a^{[l-1]}+b^{[l]}$\n",
    "        * $a^{[l]}=g^{[l]}(z^{[l]})$\n",
    "    * Vec. cal.:\n",
    "        * $Z^{[l]}=W^{[l]}\\cdot A^{[l-1]}+b^{[l]}$\n",
    "        * $A^{[l]}=g^{[l]}(Z^{[l]})$\n",
    "        * $X=A^{[0]}$\n",
    "* Backward\n",
    "    * Input: $da^{[l]}$\n",
    "    * Output: $da^{[l-1]}$, $dw^{[l]}$, $db^{[l]}$\n",
    "    * Cal eq.:\n",
    "        * $dz^{[l]}=da^{[l]}* (g^{[l]})'(z^{[l]})$\n",
    "        * $dw^{[l]}=dz^{[l]}a^{[l-1]}$\n",
    "        * $db^{[l]}=dz^{[l]}$\n",
    "        * $da^{[l-1]}=w^{[l]^T}dz^{[l]}$\n",
    "            * $dz^{[l]}=w^{[l+1]^T}dz^{[l+1]}* (g^{[l]})'(z^{[l]})$\n",
    "    * Vec. cal.:\n",
    "        * $dZ^{[l]}=dA^{[l]}* (g^{[l]})'(Z^{[l]})$\n",
    "        * $dW^{[l]}=\\frac{1}{m}dZ^{[l]}A^{[l-1]^T}$\n",
    "        * $db^{[l]}=\\frac{1}{m}np.sum(dZ^{[l]}, axis=1, keepdim=True)$\n",
    "        * $dA^{[l-1]}=W^{[l]^T}dZ^{[l]}$\n",
    "* ![img50](imgs/img50.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Parameters vs. hyper-parameters\n",
    "\n",
    "* Para.\n",
    "    * W, b\n",
    "* Hyper-para.\n",
    "    * learning rate $\\alpha$\n",
    "    * #of iterations\n",
    "    * #of hidden layers $L$\n",
    "    * #of hidden units  $n^{[l]}$\n",
    "    * choice of activation function\n",
    "    * Momentom\n",
    "    * minibathc size\n",
    "    * regularizations\n",
    "    * etc.\n",
    "    \n",
    "* Empirical process\n",
    "    * try different value and saw the cost \n",
    "    * ![img51](imgs/img51.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL w/ the brain\n",
    "\n",
    "* ![img52](imgs/img52.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
